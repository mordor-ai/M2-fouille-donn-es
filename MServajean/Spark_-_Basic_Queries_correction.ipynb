{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "spark = SparkSession.builder.appName(\"Python Spark\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings = spark.read\\\n",
    "    .option(\"delimiter\", \"\\t\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .csv('data/u.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- item_id: integer (nullable = true)\n",
      " |-- rating: integer (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the dataframe schema\n",
    "df_ratings.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+---------+\n",
      "|user_id|item_id|rating|timestamp|\n",
      "+-------+-------+------+---------+\n",
      "|    196|    242|     3|881250949|\n",
      "|    186|    302|     3|891717742|\n",
      "|     22|    377|     1|878887116|\n",
      "|    244|     51|     2|880606923|\n",
      "|    166|    346|     1|886397596|\n",
      "+-------+-------+------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show a sample of the data (the dataframe executes the whole pipeline at this stage)\n",
    "df_ratings.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the rdd equivalent of the dataframe\n",
    "rdd_ratings = df_ratings.rdd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice 1 - Number of movies per user (using RDD then Dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculer pour chaque utilisateur le nombre de films notés, et afficher le résultat pour l'un d'entre eux. Utilisez dans un premier temps les RDD puis les Dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(196, 39)]\n"
     ]
    }
   ],
   "source": [
    "# classical RDD approach\n",
    "result_1 = rdd_ratings.map(lambda r: (r[0], 1)).reduceByKey(lambda v1, v2: v1 + v2).take(1)\n",
    "print(result_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|user_id|count|\n",
      "+-------+-----+\n",
      "|    196|   39|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dataframe approach, filtering on the previous user to compare results\n",
    "df_ratings.filter(df_ratings['user_id']==result_1[0][0])\\\n",
    "    .groupBy('user_id')\\\n",
    "    .count()\\\n",
    "    .show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice 2 - Average rating per user (using RDD then Dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculer pour chaque utilisateurs la note moyenne donnée et afficher le résultat pour l'un d'entre eux. Utilisez dans un premier temps les RDD puis les Dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(196, 3.6153846153846154)]\n"
     ]
    }
   ],
   "source": [
    "# classical RDD approach\n",
    "rdd_map = rdd_ratings.map(lambda r: (r[0], int(r[2])))\n",
    "rdd_agg = rdd_map = rdd_map.aggregateByKey(\n",
    "    (0, 0), \n",
    "    lambda a,b: (a[0] + b,    a[1] + 1), \n",
    "    lambda a,b: (a[0] + b[0], a[1] + b[1])\n",
    ")\n",
    "\n",
    "rdd_result = rdd_agg.mapValues(lambda v: float(v[0])/v[1])\n",
    "\n",
    "result_1 = rdd_result.take(1)\n",
    "print(result_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|user_id|       avg(rating)|\n",
      "+-------+------------------+\n",
      "|    196|3.6153846153846154|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dataframe approach\n",
    "from pyspark.sql.functions import avg\n",
    "\n",
    "df_ratings.filter(df_ratings['user_id']==result_1[0][0])\\\n",
    "    .groupBy('user_id')\\\n",
    "    .agg(avg('rating'))\\\n",
    "    .show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice 3 - Top-5 movies with at least 15 votes (Dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afficher les 5 meilleurs films parmi ceux qui ont reçu au moins 15 votes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Indices:*\n",
    "* Utiliser df_ratings pour calculer la moyenne, filtrer les films qui ont moins de 15 notes et classer les films par ordre décroissant.\n",
    "* Faire un join avec df_movies pour afficher le nom des films sélectionnés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items = spark.read\\\n",
    "    .option(\"delimiter\", \"|\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .csv('data/u.item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg, count, col\n",
    "\n",
    "df_gb = df_ratings.groupBy('item_id')\\\n",
    "    .agg(avg('rating'), count('item_id').alias('count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gb = df_gb.filter(df_gb['count'] >= 15).sort(\"avg(rating)\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join with actual movie features\n",
    "df_join = df_gb.join(df_items, df_gb['item_id']==df_items['movie_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+\n",
      "|         movie_title|      avg(rating)|\n",
      "+--------------------+-----------------+\n",
      "|Close Shave, A (1...|4.491071428571429|\n",
      "|Schindler's List ...|4.466442953020135|\n",
      "|Wrong Trousers, T...|4.466101694915254|\n",
      "|   Casablanca (1942)| 4.45679012345679|\n",
      "|Wallace & Gromit:...|4.447761194029851|\n",
      "+--------------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_join.select(col(\"movie_title\"), col(\"avg(rating)\")).show(5)  # Java 8 (does not work with Java 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
