{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import findspark\n",
    "# findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Python Spark\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transactions = spark.read.option(\"header\", True)\\\n",
    "    .option(\"delimiter\", \"|\")\\\n",
    "    .option(\"delimiter\", \",\")\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .csv('data/train.csv')\\\n",
    "    .withColumnRenamed('default_payment_next_month', 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- LIMIT_BAL: decimal(7,0) (nullable = true)\n",
      " |-- SEX: integer (nullable = true)\n",
      " |-- EDUCATION: integer (nullable = true)\n",
      " |-- MARRIAGE: integer (nullable = true)\n",
      " |-- AGE: integer (nullable = true)\n",
      " |-- PAY_0: integer (nullable = true)\n",
      " |-- PAY_2: integer (nullable = true)\n",
      " |-- PAY_3: integer (nullable = true)\n",
      " |-- PAY_4: integer (nullable = true)\n",
      " |-- PAY_5: integer (nullable = true)\n",
      " |-- PAY_6: integer (nullable = true)\n",
      " |-- BILL_AMT1: decimal(6,0) (nullable = true)\n",
      " |-- BILL_AMT2: decimal(6,0) (nullable = true)\n",
      " |-- BILL_AMT3: decimal(7,0) (nullable = true)\n",
      " |-- BILL_AMT4: decimal(6,0) (nullable = true)\n",
      " |-- BILL_AMT5: decimal(6,0) (nullable = true)\n",
      " |-- BILL_AMT6: decimal(6,0) (nullable = true)\n",
      " |-- PAY_AMT1: decimal(6,0) (nullable = true)\n",
      " |-- PAY_AMT2: decimal(7,0) (nullable = true)\n",
      " |-- PAY_AMT3: decimal(6,0) (nullable = true)\n",
      " |-- PAY_AMT4: decimal(6,0) (nullable = true)\n",
      " |-- PAY_AMT5: decimal(6,0) (nullable = true)\n",
      " |-- PAY_AMT6: decimal(6,0) (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_transactions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = df_transactions.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"MARRIAGE\", \"EDUCATION\", \"PAY_0\", \"PAY_2\", \"PAY_3\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "lr = LogisticRegression(maxIter=10, regParam=10.0, elasticNetParam=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[assembler, lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- LIMIT_BAL: decimal(7,0) (nullable = true)\n",
      " |-- SEX: integer (nullable = true)\n",
      " |-- EDUCATION: integer (nullable = true)\n",
      " |-- MARRIAGE: integer (nullable = true)\n",
      " |-- AGE: integer (nullable = true)\n",
      " |-- PAY_0: integer (nullable = true)\n",
      " |-- PAY_2: integer (nullable = true)\n",
      " |-- PAY_3: integer (nullable = true)\n",
      " |-- PAY_4: integer (nullable = true)\n",
      " |-- PAY_5: integer (nullable = true)\n",
      " |-- PAY_6: integer (nullable = true)\n",
      " |-- BILL_AMT1: decimal(6,0) (nullable = true)\n",
      " |-- BILL_AMT2: decimal(6,0) (nullable = true)\n",
      " |-- BILL_AMT3: decimal(7,0) (nullable = true)\n",
      " |-- BILL_AMT4: decimal(6,0) (nullable = true)\n",
      " |-- BILL_AMT5: decimal(6,0) (nullable = true)\n",
      " |-- BILL_AMT6: decimal(6,0) (nullable = true)\n",
      " |-- PAY_AMT1: decimal(6,0) (nullable = true)\n",
      " |-- PAY_AMT2: decimal(7,0) (nullable = true)\n",
      " |-- PAY_AMT3: decimal(6,0) (nullable = true)\n",
      " |-- PAY_AMT4: decimal(6,0) (nullable = true)\n",
      " |-- PAY_AMT5: decimal(6,0) (nullable = true)\n",
      " |-- PAY_AMT6: decimal(6,0) (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "evaluator_roc = BinaryClassificationEvaluator(\n",
    "    labelCol='label', \n",
    "    rawPredictionCol='rawPrediction',\n",
    "    metricName='areaUnderROC'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC = 0.6825956971417326\n"
     ]
    }
   ],
   "source": [
    "print('Area under ROC = %s' % evaluator_roc.evaluate(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stream will be produced by ```generate_transactions.py```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.streaming import StreamingContext\n",
    "\n",
    "ssc = StreamingContext(sc, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(time, rdd):\n",
    "    print(\"========= %s =========\" % str(time))\n",
    "    try:\n",
    "\n",
    "        # Convert RDD[String] to DataFrame\n",
    "        rdd_proper = rdd.map(lambda line: line.split(','))\n",
    "\n",
    "        df_stream = spark.createDataFrame(rdd_proper)\n",
    "        \n",
    "        # changing schema\n",
    "        for c, i in zip(df_stream.columns, train.schema):\n",
    "            df_stream = df_stream.withColumn(i.name, df_stream[c].cast(i.dataType))\n",
    "            \n",
    "        if df_stream.count() > 0:\n",
    "            predictions = model.transform(df_stream)\n",
    "            print(\n",
    "                'Area under ROC = %s (with %ld elements)' % (evaluator_roc.evaluate(predictions), df_stream.count())\n",
    "            )\n",
    "    except Exception as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= 2019-08-24 17:53:29 =========\n",
      "RDD is empty\n",
      "========= 2019-08-24 17:53:30 =========\n",
      "Area under ROC = 0.6372881355932203 (with 143 elements)\n",
      "========= 2019-08-24 17:53:31 =========\n",
      "RDD is empty\n",
      "========= 2019-08-24 17:53:32 =========\n",
      "Area under ROC = 0.7389446302489785 (with 140 elements)\n",
      "========= 2019-08-24 17:53:33 =========\n",
      "RDD is empty\n",
      "========= 2019-08-24 17:53:34 =========\n",
      "Area under ROC = 0.7580645161290323 (with 37 elements)\n",
      "========= 2019-08-24 17:53:35 =========\n",
      "RDD is empty\n",
      "========= 2019-08-24 17:53:36 =========\n",
      "Area under ROC = 0.7276995305164321 (with 86 elements)\n",
      "========= 2019-08-24 17:53:37 =========\n",
      "RDD is empty\n",
      "========= 2019-08-24 17:53:38 =========\n",
      "Area under ROC = 0.6388888888888888 (with 15 elements)\n",
      "========= 2019-08-24 17:53:39 =========\n",
      "RDD is empty\n",
      "========= 2019-08-24 17:53:40 =========\n",
      "Area under ROC = 0.4365079365079365 (with 16 elements)\n",
      "========= 2019-08-24 17:53:41 =========\n",
      "RDD is empty\n",
      "========= 2019-08-24 17:53:42 =========\n",
      "Area under ROC = 0.5946428571428571 (with 43 elements)\n",
      "========= 2019-08-24 17:53:43 =========\n",
      "RDD is empty\n",
      "========= 2019-08-24 17:53:44 =========\n",
      "Area under ROC = 0.7056034482758621 (with 136 elements)\n",
      "========= 2019-08-24 17:53:45 =========\n",
      "RDD is empty\n",
      "========= 2019-08-24 17:53:46 =========\n",
      "Area under ROC = 0.6848484848484848 (with 56 elements)\n",
      "========= 2019-08-24 17:53:47 =========\n",
      "RDD is empty\n"
     ]
    }
   ],
   "source": [
    "stream = ssc.textFileStream('data/output/')\n",
    "\n",
    "stream.foreachRDD(process)\n",
    "\n",
    "ssc.start()\n",
    "# ssc.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop stream\n",
    "ssc.stop(True, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
