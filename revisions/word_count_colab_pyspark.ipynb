{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "word_count_colab_pyspark.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOAcJh1U3LXb2RkLaa15hEL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mordor-ai/M2-fouille-donn-es/blob/master/revisions/word_count_colab_pyspark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WN6LJ2iAQgZa",
        "outputId": "e40dd06f-1e4d-4486-898c-2decaf2e6aab"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huccYUYWQz72"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwNcTV3qagKv"
      },
      "source": [
        "!chmod 755 /content/drive/MyDrive/spark-3.0.1-bin-hadoop2.7/bin/*"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCJYXPCT4tp9",
        "outputId": "88407f67-2b08-440d-8a60-a1c22b96f59d"
      },
      "source": [
        "!pip install -q findspark\r\n",
        "!pip install -q pyspark\r\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 204.2MB 65kB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 47.4MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "op1hJKo5QdgG"
      },
      "source": [
        "import os\r\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\r\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/drive/MyDrive/spark-3.0.1-bin-hadoop2.7\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bKTL8xvRGnR"
      },
      "source": [
        "from pyspark import SparkContext\r\n",
        "sc = SparkContext()\r\n",
        "lines = sc.textFile(\"text.txt\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G87VwtysS6_B"
      },
      "source": [
        "!echo \"Sur mes cahiers d'écolier Sur mon pupitre et les arbres Sur le sable de neige J'écris ton nom\" > text.txt\r\n",
        "!echo \"Sur les pages lues Sur toutes les pages blanches Pierre sang papier ou cendre J'écris ton nom\" >> text.txt\r\n",
        "!echo \"Sur les images dorées Sur les armes des guerriers Sur la couronne des rois J'écris ton nom\" >> text.txt"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9tUkb1aQ8iT"
      },
      "source": [
        "# Décomposition de chaque ligne en mots\r\n",
        "word_counts = lines.flatMap(lambda line: line.split(' ')).map(lambda word: (word, 1)).reduceByKey(lambda count1, count2: count1 + count2).collect()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDHpjAYxRe7m",
        "outputId": "a0047eb8-7dfa-4bf9-fd06-19eab239ea40"
      },
      "source": [
        "for(word,count) in word_counts:\r\n",
        "  print(word,count)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mes 1\n",
            "cahiers 1\n",
            "mon 1\n",
            "les 5\n",
            "le 1\n",
            "J'écris 3\n",
            "ton 3\n",
            "lues 1\n",
            "Pierre 1\n",
            "ou 1\n",
            "des 2\n",
            "guerriers 1\n",
            "Sur 8\n",
            "d'écolier 1\n",
            "pupitre 1\n",
            "et 1\n",
            "arbres 1\n",
            "sable 1\n",
            "de 1\n",
            "neige 1\n",
            "nom 3\n",
            "pages 2\n",
            "toutes 1\n",
            "blanches 1\n",
            "sang 1\n",
            "papier 1\n",
            "cendre 1\n",
            "images 1\n",
            "dorées 1\n",
            "armes 1\n",
            "la 1\n",
            "couronne 1\n",
            "rois 1\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}